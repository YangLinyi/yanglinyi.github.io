---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}


<span class='anchor' id='about-me'></span>

<span style="color:red; font-size: 100%">**Actively Employing 26 Fall Masters, and PhDs**</span>


My research interests are building AI co-scientists, enhancing LLMs' reasoning capabilities, and designing **open-ended curiosity-driven exploration-based** methods. If you are looking for research positions, please do not hesitate to contact me via email: yanglinyiucd[at]gmail[dot]com  

I was fortunate to be supervised by Prof. Jun Wang (UCL), Prof. Barry Smyth (UCD), and Prof. Yue Zhang (Westlake). I served as an **Area Chair** at ICLR, ACL, EMNLP, and CIKM, a **Senior Program Committee** member at IJCAI, and an **Associate Editor** at the Special Issue on TIST with Prof. Jindong Wang and Prof. Qiang Yang. I have published some influential papers at top-tier conferences and have been featured by Huggingface and social media multiple times, with a total citation: <a href='https://scholar.google.com/citations?user=go3sFxcAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>.

I designed the first LLM-based Research-Review-Refinement process by using reinforcement learning, namely CycleResearcher [ICLR, 2025]. I tried to pre-train a large-scale graph recurrent network, instead of using transformers, achieving the state-of-the-art results [TPAMI, 2025]. Before ChatGPT, I built the first large-scale out-of-distribution natural language understanding dataset, namely GLUE-X [ACL, 2023]. 

Currently, I devote myself to **AI for Scientific Discovery**.


# üèÜ Honors and Awards
- Faculty and lecturer at the International Programme on [AI Evaluation](https://ai-evaluation.org): Capabilities & Safety
- Area Chair: **ICLR 2025; ACL 2024-2025; EMNLP 2023; IJCAI 2023 (SPC); CIKM 2022**;  Associate Editor: TIST.
- Outstanding Postdoctoral Representative, 2023.
- Outstanding Postdoc Researcher, 2022.
- Outstanding Self-financed Students Abroad (Special Awards, Only 1 Winner in Ireland, 50 Winners in total), 2021.
- Best Paper Candidate, CCIS, 2018.

# ![image](https://github.com/user-attachments/assets/1507999a-4319-439c-9bea-87ce7ac91f51) Team Members

- PhD Students:
  
  Jiayao Chen (Shenzhen University)

  Jiayao Fu (Fudan University)
  
  Shi Liu (Hong Kong University)

- Master Students:

  Junhao Ma (SUSTech)

  Lang Yang (South China University of Technology)

- Research Assistants:

  Qi Zhang (Oxford University)
  
  Zihan Wang (Tsinghua University (Shenzhen))

  Lam Nguyen (Tsinghua University (Shenzhen))

  Huichi Zhou (Impirical College London)

  Guanghao Jin (LMU)

  Yanyun Liu (HKUST)

  Yuhao Wang (NUS)

  Zhichen Zhao (HKUST)

  Xinyu Zhou (HKU)


# Repository
[ **[AgentFly](https://github.com/Agent-on-the-Fly/Memento)** ![](https://img.shields.io/github/stars/Agent-on-the-Fly/Memento?style=social&label=Stars) | **[OpenR](https://github.com/openreasoner/openr)** ![](https://img.shields.io/github/stars/openreasoner/openr?style=social&label=Stars) | **[CycleResearcher](https://github.com/zhu-minjun/Researcher)** ![](https://img.shields.io/github/stars/zhu-minjun/Researcher?style=social&label=Stars) | **[LLM-Eval](https://github.com/MLGroupJLU/LLM-eval-survey)** ![](https://img.shields.io/github/stars/MLGroupJLU/LLM-eval-survey?style=social&label=Stars)]


# News
- 2025-Dec One paper has been accepted to **TASLP** (Multilingual Cultural Evaluation of LLMs).
- 2025-Nov Served as the **Best Paper Committee Chair** at [ICAIS 2025](https://icais.ai/).
- 2025-Sep **Three papers** have been accepted to [NeurIPS 2025](https://neurips.cc/).
- 2025-Aug **Two papers** have been accepted to [EMNLP 2025](https://2025.emnlp.org/), including an **oral** paper (ResearStudio).
- 2025-Aug We released **Memento**, the open-source framework that achieves the state-of-the-art results on **GAIA**.
- 2025-Jul Feature-level alignment (FPO) has been accepted to [ICML 2025](https://icml.cc/virtual/2025/poster/46128).
- 2025-Jan **Six papers** have been accepted to the main conference of [ICLR 2025](https://iclr.cc/), including an **oral** paper.
- 2024-Dec I served as an **Area Chair** at ACL 2025 and ICLR 2025.
- 2024-Nov We gave the tutorial on LLM Evaluation at **AAAI 2024** and **CVPR 2025**.
- 2024-Oct I have been invited to give a 6-hour tutorial at **RL China 2024**.
- 2024-May Two papers have been accepted to the main conference of [ACL 2024](https://2024.aclweb.org/).
- 2024-Feb One paper has been accepted to [NAACL 2024](https://2024.naacl.org/) (Rationale-centric Counterfactual Data Augmentation).
- 2024-Jan Three papers (**SuperContext**, FastDetect, and PandaLM) have been accepted to [ICLR 2024](https://iclr.cc/).
- 2023-Dec One paper has been accepted to [EMNLP 2023](https://2023.emnlp.org/).
- 2023-Nov Organized ACM TIST Special Issue on Evaluations of Large Language Model with Dr. Jindong Wang and Prof. Qiang Yang.
- 2023-May Four papers have been accepted to [ACL 2023](https://2023.aclweb.org/) (Three leading author papers).
- 2023-Apr Our paper discussing the robustness of ChatGPT has been accepted to [ICLR 2023](https://arxiv.org/abs/2302.12095) Workshop.
- Area Chair / Senior Programme Committee (SPC): EMNLP-22; CIKM-22; IJCAI-23; ACL-25.
- PC Member/Reviewer: CIKM-20; SIGIR-21; CKIM-21; EMNLP 2021-2024; ACL 2021-2024; COLING 2022-2024; TASLP; TALLIP; TBD; TKDE.


# üìù Publications

___* denotes equal contribution___
___+ denotes corresponding author___

- (45) Constrain Alignment with Sparse Autoencoders

  Qingyu Yin, Chak Tou Leong, Hongbo Zhang, Minjun Zhu, Hanqi Yan, Qiang Zhang, Yulan He, Wenjie Li, Jun Wang, Yue Zhang, **Linyi Yang**

  Forty-Second International Conference on Machine Learning (<font color=Blue>``ICML 2025, CCF-A``</font>). 

- (44) DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process

  Minjun Zhu, Yixuan Weng, **Linyi Yang**, Yue Zhang

  The 62nd Annual Meeting of the Association for Computational Linguistics (<font color=Blue>``ACL 2025, CCF-A``</font>). 

- (43) Pre-Training a Graph Recurrent Network for Text Understanding

  Yile Wang, **Linyi Yang**, Zhiyang Teng, Ming Zhou, Yue Zhang

  IEEE Transactions on Pattern Analysis and Machine Intelligence 2025 (<font color=Blue>``TPAMI, CCF-A``</font>). 

- (42) An Empirical Analysis of Uncertainty in Large Language Model Evaluations.
  
  Qiujie Xie, Qingqiu Li, Zhuohao Yu, Yuejie Zhang, Yue Zhang, **Linyi Yang+**.

  International Conference on Learning Representations 2025 (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).
  
- (41) CycleResearcher: Improving Automated Research via Automated Review.
  
  Yixuan Weng, Minjun Zhu, Guangsheng Bao, Hongbo Zhang, Jindong Wang, Yue Zhang+, **Linyi Yang+**.
  
  International Conference on Learning Representations 2025 (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).

- (40) Personality Alignment of Large Language Models.
  
  Minjun Zhu, Yixuan Weng, **Linyi Yang**, Yue Zhang.
  
  International Conference on Learning Representations 2025 (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).

- (39) MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions.
  
  Jian Wu, **Linyi Yang**, Dongyuan Li, Yuliang Ji, Manabu Okumura, Yue Zhang.
  
  International Conference on Learning Representations 2025 (average score: 8, top 20) (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).

- (38) CofCA: A STEP-WISE Counterfactual Multi-hop QA benchmark.
  
  Jian Wu, **Linyi Yang**, Zhen Wang, Manabu Okumura, Yue Zhang.
  
  International Conference on Learning Representations 2025 (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).

- (37) Human Simulacra: Benchmarking the Personification of Large Language Models.
  
  Qiujie Xie, Qiming Feng, Tianqi Zhang, Qingqiu Li, **Linyi Yang**, Yuejie Zhang, Rui Feng, Liang He, Shang Gao, Yue Zhang.
  
  International Conference on Learning Representations 2025 (<font color=Blue>``ICLR 2025, Tsinghua-A``</font>).

- (36) PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts. [\[paper\]](https://arxiv.org/abs/2306.04528); [![](https://img.shields.io/github/stars/microsoft/promptbench?style=social&label=Code+Stars)](https://github.com/microsoft/promptbench)
  
  Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, **Linyi Yang**, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, Xing Xie.

  1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis (<font color=Blue>``CCS Workshop``</font>).

- (35) Detoxifying Large Language Models via Knowledge Editing. [\[paper\]](https://arxiv.org/pdf/2403.14472)

  Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, **Linyi Yang**, Jindong Wang, Huajun Chen.

  The 62nd Annual Meeting of the Association for Computational Linguistics (<font color=Blue>``ACL 2024, CCF-A``</font>).

- (34) Deepfake text detection in the wild. [\[paper\]](https://arxiv.org/pdf/2305.13242)

  Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue Wang, **Linyi Yang**, Shuming Shi, Yue Zhang.

  The 62nd Annual Meeting of the Association for Computational Linguistics (<font color=Blue>``ACL 2024, CCF-A``</font>).

- (33) A Rationale-centric Counterfactual Data Augmentation Method for Cross-Document Event Coreference Resolution. [\[paper\]](https://arxiv.org/abs/2404.01921)
  
  Bowen Ding, Qingkai Min, Shengkun Ma, Yingjie Li, **Linyi Yang‚Ä†**, Yue Zhang.
  
  Annual Conference of the North American Chapter of the Association for Computational Linguistics 2024 (<font color=Blue>``NAACL 2024``</font>).

- (32) PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization. [\[paper\]](https://arxiv.org/abs/2306.05087); [![](https://img.shields.io/github/stars/WeOpenML/PandaLM?style=social&label=Code+Stars)](https://github.com/WeOpenML/PandaLM)
  
  Yidong Wang, Zhuohao Yu, Zhengran Zeng, **Linyi Yang**, Cunxiang Wang, Hao Chen, Chaoya Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye, Shikun Zhang, Yue Zhang.
  
  International Conference on Learning Representations 2024 (<font color=Blue>``ICLR 2024, Tsinghua-A``</font>).

- (31) Supervised Knowledge Makes Large Language Models Better In-context Learners. [\[paper\]](https://arxiv.org/pdf/2312.15918.pdf)
  
  **Linyi Yang**, Shuibai Zhang, Zhuohao Yu, Guangsheng Bao, Yidong Wang, Jindong Wang, Ruochen Xu, Wei Ye, Xing Xie, Weizhu Chen, Yue Zhang.
  
  International Conference on Learning Representations 2024 (<font color=Blue>``ICLR 2024, Tsinghua-A``</font>).

- (30) Fast-DetectGPT: Efficient zero-shot detection of machine-generated text via conditional probability curvature. [\[paper\]](https://arxiv.org/abs/2310.05130.pdf)
  
  Guangsheng Bao, Yanbin Zhao, Zhiyang Teng, Linyi Yang, Yue Zhang.
  
  International Conference on Learning Representations 2024 (<font color=Blue>``ICLR 2024, Tsinghua-A``</font>).

- (29) LLMs with Chain-of-Thought Are Non-Causal Reasoners. [\[paper\]](https://arxiv.org/pdf/2402.16048)
 
   Guangsheng Bao, Hongbo Zhang, **Linyi Yang**, Cunxiang Wang, Yue Zhang.

   arXiv preprint 2024 (<font color=Blue>``COLING 2024 (Oral)``</font>). 

- (28) A Survey on Evaluation of Large Language Models. [\[paper\]](https://arxiv.org/abs/2307.03109); [![](https://img.shields.io/github/stars/MLGroupJLU/LLM-eval-survey?style=social&label=Code+Stars)](https://github.com/MLGroupJLU/LLM-eval-survey)

  Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, **Linyi Yang**, Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, Xing Xie.

  Transactions on Intelligent Systems and Technology (<font color=Blue>``TIST 2024``</font>).

- (27) Out-of-Distribution Generalization in Natural Language Processing: Past, Present, and Future. [\[paper\]](https://openreview.net/pdf?id=ivSJdhcuTi)

  **Linyi Yang**, Yaoxian Song, Xuan Ren, Chenyang Lyu, Yidong Wang, Jingming Zhuo, Lingqiao Liu, Jindong Wang, Jennifer Foster, Yue Zhang.

  The 2023 Conference on Empirical Methods in Natural Language Processing (<font color=Blue>``EMNLP 2023``</font>).

- (26) Measuring Consistency in Text-based Financial Forecasting Models. [\[paper\]](https://arxiv.org/pdf/2305.08524)

  **Linyi Yang**,Yingpeng Ma, Yue Zhang.

  The 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (<font color=Blue>``ACL 2023 (Oral)``</font>).

- (25) GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. [\[paper\]](https://arxiv.org/abs/2211.08073); [![](https://img.shields.io/github/stars/YangLinyi/GLUE-X?style=social&label=Code+Stars)](https://github.com/YangLinyi/GLUE-X)

  **Linyi Yang**, Shuibai Zhang, Libo Qin, Yafu Li, Yidong Wang, Hanmeng Liu, Jindong Wang, Xing Xie, Yue Zhang.

  Findings of the Association for Computational Linguistics: ACL 2023 (<font color=Blue>``ACL 2023, CCF-A``</font>).

- (24) Learning to Generalize for Cross-domain QA. [\[paper\]](https://arxiv.org/pdf/2305.08208)

  Yingjie Niu*, **Linyi Yang***, Ruihai Dong, Yue Zhang.

  Findings of the Association for Computational Linguistics: ACL 2023 (<font color=Blue>``ACL 2023, CCF-A``</font>).

- (23) Exploiting Rich Textual User-Product Context for Improving Personalized Sentiment Analysis. [\[paper\]](https://doras.dcu.ie/29140/1/2023.findings-acl.92.pdf)

  Chenyang Lyu, Linyi Yang, Yue Zhang, Yvette Graham, Jennifer Foster.

  Findings of the Association for Computational Linguistics: ACL 2023 (<font color=Blue>``ACL 2023, CCF-A``</font>).

- (22) On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. [\[paper\]](https://arxiv.org/abs/2302.12095); [![](https://img.shields.io/github/stars/microsoft/robustlearn?style=social&label=Code+Stars)](https://github.com/microsoft/robustlearn/tree/main/chatgpt-robust)
  
  Jindong Wang, Xixu Hu, Wenxin Hou, Hao Chen, Runkai Zheng, **Yidong Wang**, Linyi Yang, Haojun Huang, Wei Ye, Xiubo Geng, Binxin Jiao, Yue Zhang, Xing Xie.
  
  Workshop on Trustworthy and Reliable Large-Scale Machine Learning Models at ICLR 2023 (<font color=Blue>``RTML Workshop 2023``</font>).

- (21) SciMine: An Efficient Systematic Prioritization Model Based on Richer Semantic Information. [\[paper\]](https://dl.acm.org/doi/abs/10.1145/3539618.3591764)

  Fang Guo, Yun Luo, **Linyi Yang**, Yue Zhang.

  The 46th International ACM SIGIR Conference on Research and Development in Information Retrieval (<font color=Blue>``SIGIR 2023, CCF-A``</font>).

- (20) Graph-Based Video-Language Learning with Multi-Grained Audio-Visual Alignment. [\[paper\]](https://dl.acm.org/doi/proceedings/10.1145/3581783)

  Chenyang Lyu, Wenxi Li, Tianbo Ji, Longyue Wang, Liting Zhou, Cathal Gurrin, **Linyi Yang**, Yi Yu, Yvette Graham, Jennifer Foster.

  Proceedings of the 31st ACM International Conference on Multimedia (<font color=Blue>``MM 2023, CCF-A``</font>).

- (19) Survey on factuality in large language models: Knowledge, retrieval and domain-specificity. [\[paper\]](https://arxiv.org/pdf/2310.07521)

  Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, **Linyi Yang**, Jindong Wang, Xing Xie, Zheng Zhang, Yue Zhang.

  TIST (<font color=Blue>``TIST 2023``</font>).

- (18) USB: A Unified Semi-supervised Learning Benchmark for Classification. [\[paper\]](https://proceedings.neurips.cc/paper_files/paper/2022/file/190dd6a5735822f05646dc27decff19b-Paper-Datasets_and_Benchmarks.pdf)

  Yidong Wang, Hao Chen, Yue Fan, Wang Sun, Ran Tao, Wenxin Hou, Renjie Wang, **Linyi Yang**, Zhi Zhou, Lan-Zhe Guo, Heli Qi, Zhen Wu, Yu-Feng Li, Satoshi Nakamura, Wei Ye, Marios Savvides, Bhiksha Raj, Takahiro Shinozaki, Bernt Schiele, Jindong Wang, Xing Xie, Yue Zhang.

  NeurIPS Dataset and Benchmark (<font color=Blue>``NeurIPS 2022, CCF-A``</font>).

- (17) A Rationale-Centric Framework for Human-in-the-loop Machine Learning. [\[paper\]](https://arxiv.org/pdf/2203.12918)

  **Jinghui Lu***, **Linyi Yang***, Brian Mac Namee, Yue Zhang.

  ACL (<font color=Blue>``ACL 2022 (Oral), CCF-A``</font>).
  
- (16) FactMix: Using a Few Labeled In-domain Examples to Generalize to Cross-domain Named Entity Recognition. [\[paper\]](https://arxiv.org/abs/2208.11464)

  **Linyi Yang***, **Lifan Yuan***, Leyang Cui, Wenyang Gao, Yue Zhang.

  COLING (<font color=Blue>``COLING 2022 (Oral)``</font>).

- (15) NumHTML: Numeric-Oriented Hierarchical Transformer Model for Multi-task Financial Forecasting. [\[paper\]](https://arxiv.org/abs/2201.01770)

  **Linyi Yang**, Jiazheng Li, Ruihai Dong, Yue Zhang, Barry Smyth.

  AAAI (<font color=Blue>``AAAI 2022 (Oral), CCF-A``</font>).
  
- (14)  Towards Fine-grained Causal Reasoning and QA. [\[paper\]](https://arxiv.org/abs/2204.07408)

  **Linyi Yang**, Zhen Wang, Yuxiang Wu, Jie Yang, Yue Zhang.

  Asking ''Why'' Questions (<font color=Blue>``Arxiv 2022``</font>).

- (13)  Exploring the Efficacy of Automatically Generated Counterfactuals for Sentiment Analysis. [\[paper\]](https://arxiv.org/pdf/2106.15231)

  **Linyi Yang**, Jiazheng Li, P√°draig Cunningham, Yue Zhang, Barry Smyth, Ruihai Dong.

  We propose an alternative to automatically generating counterfactual data for data augmentation and explanation. (<font color=Blue>``ACL 2021 (Oral), CCF-A``</font>).

- (12)  Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classification. [\[paper\]](https://arxiv.org/pdf/2010.12512)

  **Linyi Yang**, Eoin M Kenny, Tin Lok James Ng, Yi Yang, Barry Smyth, Ruihai Dong.

  This paper proposes a novel methodology for producing plausible counterfactual explanations (<font color=Blue>``COLING 2020 (Oral)``</font>).

- (11)  MAEC: A Multimodal Aligned Earnings Conference Call Dataset for Financial Risk Prediction. [\[paper\]](https://dl.acm.org/doi/abs/10.1145/3340531.3412879)

  **Linyi Yang**, Jiazheng Li, Barry Smyth, Ruihai Dong.

  We introduce a new, large-scale, multi-modal, text-audio paired, earnings-call dataset named MAEC, based on S&P 1500 companies.  (<font color=Blue>``CIKM 2020 (Oral)``</font>).

- (10)  HTML: Hierarchical Transformer-based Multi-task Learning for Volatility Prediction. [\[paper\]](https://dl.acm.org/doi/abs/10.1145/3366423.3380128)

  **Linyi Yang**, Tin Lok James Ng, Barry Smyth, Ruihai Dong.
  
  This paper proposes a novel hierarchical, transformer, multi-task architecture to harness the text and audio data from quarterly earnings conference calls to predict future price volatility. (<font color=Blue>``WWW 2020 (Oral), CCF-A``</font>).
  
# üé§ Invited Talks
- Shanghai Chuangzhi Lab, Shanghai, Sep. 2025
- Shanghai Jiaotong University, Shanghai, Sep. 2025
- SUSTech, Shenzhen, Apr. 2025
- Zhejiang Lab, Hangzhou, Oct. 2024
- Nanjing University, Nanjing, May. 2024
- HKUST (GZ), Guangzhou, Mar. 2024
- HKUST, Hong Kong, Mar. 2024
- MSRA, Online, 2023
- Shanghai AI Lab, Shanghai, China 2023
- MLNLP, Online, China 2022
- MSRA, Online, 2022





